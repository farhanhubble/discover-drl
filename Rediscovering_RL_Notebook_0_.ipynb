{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rediscovering RL- Notebook 0 .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3D9rAcPoRhwpZb9hIEug7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhanhubble/discover-drl/blob/master/Rediscovering_RL_Notebook_0_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcMMYrax7MVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = 'âš½'\n",
        "opponent = 'ðŸ‘•'\n",
        "goal = 'ðŸ¥…'\n",
        "\n",
        "arena = [['âš½', ' ' , 'ðŸ‘•', ' ' ],\n",
        "         [' ' , ' ' , ' ' , 'ðŸ‘•'],\n",
        "         [' ' , 'ðŸ‘•', ' ' , ' ' ],\n",
        "         [' ' , ' ' , ' ' , 'ðŸ‘•'],\n",
        "         [' ' , 'ðŸ‘•', ' ' , 'ðŸ¥…']]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faVO8xdj7ZLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Foolsball(object):\n",
        "\n",
        "  def __to_state__(self,row,col):\n",
        "    \"\"\"Convert from integer state to indices (row,col).\"\"\"\n",
        "    return row*self.n_cols + col\n",
        "\n",
        "  def __to_indices__(self, state):\n",
        "    \"\"\"Convert indices(row,col) to state (single integer).\"\"\"\n",
        "    row = state // self.n_cols\n",
        "    col = state % self.n_cols\n",
        "    return row,col\n",
        "\n",
        "  def __deserialize__(self,map:list,agent:str,opponent:str, goal:str):\n",
        "    \"\"\"Convrt a string representation of a map into a 2D numpy array\n",
        "    Param map: list of lists of strings representing the player, opponents and goal.\n",
        "    Param agent: string representing the agent on the map \n",
        "    Param opponent: string representing every instance of an opponent player\n",
        "    Param goal: string representing the location of the goal on the map\n",
        "    \"\"\"\n",
        "    ## Capture dimensions and map.\n",
        "    self.n_rows = len(map)\n",
        "    self.n_cols = len(map[0])\n",
        "    self.n_states = self.n_rows * self.n_cols \n",
        "    self.map = np.asarray(map)\n",
        "\n",
        "    ## Store string representations for printing the map, etc.\n",
        "    self.agent_repr = agent\n",
        "    self.opponent_repr  = opponent\n",
        "    self.goal_repr = goal\n",
        "\n",
        "    ## Find initial state, the desired goal state and the state of the opponents. \n",
        "    self.init_state = None\n",
        "    self.goal_state = None\n",
        "    self.opponents_states = []\n",
        "\n",
        "    for row in range(self.n_rows):\n",
        "      for col in range(self.n_cols):\n",
        "        if map[row][col] == agent:\n",
        "          # Store the initial state outside the map.\n",
        "          # This helps in quickly resetting the game to the initial state and\n",
        "          # also simplifies printing the map independent of the agent's state. \n",
        "          self.init_state = self.__to_state__(row,col)\n",
        "          self.map[row,col] = ' ' \n",
        "        \n",
        "        elif map[row][col] == opponent:\n",
        "          self.opponents_states.append(self.__to_state__(row,col))\n",
        "\n",
        "        elif map[row][col] == goal:\n",
        "          self.goal_state = self.__to_state__(row,col)\n",
        "\n",
        "    assert self.init_state is not None, print(f\"Map {map} does not specify an agent {agent} location\")\n",
        "    assert self.goal_state is not None,  print(f\"Map {map} does not specify a goal {goal} location\")\n",
        "    assert self.opponents_states,  print(f\"Map {map} does not specify any opponents {opponent} location\")\n",
        "\n",
        "    return self.init_state\n",
        "\n",
        "\n",
        "  def __get_next_state_on_action__(self,state,action):\n",
        "    \"\"\"Return next state based on current state and action.\"\"\"\n",
        "    row, col = self.__to_indices__(state)\n",
        "    action_to_index_delta = {'n':[-1,0], 'e':[0,+1], 'w':[0,-1], 's':[+1,0]}\n",
        "\n",
        "    row_delta, col_delta = action_to_index_delta[action]\n",
        "    new_row , new_col = row+row_delta, col+col_delta\n",
        "\n",
        "    ## Return current state if next state is invalid\n",
        "    ## The caller need to check for this\n",
        "    if not(0<=new_row<self.n_rows) or not(0<=new_col<self.n_cols):\n",
        "      return state  \n",
        "    \n",
        "    return self.__to_state__(new_row, new_col)\n",
        "\n",
        "  \n",
        "  def __init__(self,map,agent,opponent,goal):\n",
        "    \"\"\"Spawn the world, create variables to track state and actions.\"\"\"\n",
        "    # We just need to track the location of the agent (the ball)\n",
        "    # Everything else is static and so a potential algorithm doesn't \n",
        "    # have to look at it. The `done` flag terminal states.\n",
        "    self.state = self.__deserialize__(map,agent,opponent,goal)\n",
        "    self.done = False\n",
        "    self.actions = ['n','e','w','s']\n",
        "\n",
        "    # Build a trnasition table (dict of dicts), mapping every (state,action)\n",
        "    # pair to the next state. This defines the one-step dynamics of the \n",
        "    # environment \n",
        "    self.transitions = self.__install_transition_table__()\n",
        "\n",
        "\n",
        "    # Set up the rewards\n",
        "    self.rewards = {'unmarked':-1, 'opponent':-5, 'outside':-1, 'goal':+5}\n",
        "\n",
        "  \n",
        "  def __install_transition_table__(self):\n",
        "    ## Create a dictionary of dictionaries that can map every (state,action) pair\n",
        "    ## to the corresponding next state.\n",
        "    transitions = {s:{a:None for a in self.actions} for s in range(self.n_states)}\n",
        "    for s in range(self.n_states):\n",
        "      for a in self.actions:\n",
        "        transitions[s][a] = self.__get_next_state_on_action__(s,a)\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Reset the environment to its initial state.\"\"\"\n",
        "    # There's really just two things we need to reset: the state, which should\n",
        "    # be reset to the initial state, and the `done` flag which should be \n",
        "    # cleared to signal that we are not in a terminal state anymore, even if we \n",
        "    # were earlier. \n",
        "    self.state = self.init_state\n",
        "    self.done  = False\n",
        "    return self.state\n",
        "\n",
        "  \n",
        "  def step(self,action):\n",
        "    \"\"\"Simulate state transition based on current state and action received.\"\"\"\n",
        "    assert not self.done, \\\n",
        "    print(f'You cannot call step() in a terminal state({self.state}). Check the \"done\" flag before calling step() to avoid this.')\n",
        "    next_state = self.__get_next_state_on_action__(self.state, action)\n",
        "\n",
        "    ## Transition rejected due to illegal action (move)\n",
        "    if next_state == self.state:\n",
        "      reward = self.rewards['outside']\n",
        "      done = False\n",
        "    \n",
        "    ## Goal!\n",
        "    elif next_state == self.goal_state:\n",
        "      reward = self.rewards['goal']\n",
        "      done = True\n",
        "    \n",
        "    ## Ran into opponent. \n",
        "    elif next_state in self.opponents_states:\n",
        "      reward = self.rewards['opponent']\n",
        "      done = True\n",
        "\n",
        "    ## Made a safe and valid move.   \n",
        "    else:\n",
        "      reward = self.rewards['unmarked']\n",
        "      done = False\n",
        "\n",
        "    self.state, self.done = next_state, done\n",
        "    return next_state, reward, done\n",
        "\n",
        "\n",
        "  def render(self):\n",
        "    \"\"\"Pretty-print the environment and agent.\"\"\"\n",
        "    for row in range(self.map.shape[0]):\n",
        "      for col in range(self.map.shape[1]):\n",
        "        ## Goal location.\n",
        "        if (row,col) == self.__to_indices__(self.goal_state):\n",
        "          if self.state == self.goal_state:\n",
        "            print(f' ðŸ ',end=\"\")\n",
        "          else:\n",
        "            print(f' {self.goal_repr}',end=\"\")\n",
        "        \n",
        "        ## One of the opponent positions.\n",
        "        elif self.__to_state__(row,col) in self.opponents_states:\n",
        "          if (row,col) == self.__to_indices__(self.state): \n",
        "            print(' â— ',end='')\n",
        "          else:\n",
        "            print(f' {self.opponent_repr}',end=\"\")\n",
        "\n",
        "        ## Agent's current position.\n",
        "        elif (row,col) == self.__to_indices__(self.state):\n",
        "          if self.state == self.goal_state:\n",
        "            print(f' ðŸ ',end=\"\")\n",
        "          else:\n",
        "            print(f'{self.agent_repr} ',end=\"\")    \n",
        "\n",
        "        ## Unoccupied position.\n",
        "        else:\n",
        "          print(' + ',end=\"\") \n",
        "      \n",
        "      print('\\n') \n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK5uEU1QGddR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foolsball = Foolsball(arena, agent, opponent, goal)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-73dioBddqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foolsball.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4w1HCRHwG60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  try:\n",
        "    act = input('>>')\n",
        "\n",
        "    if act in foolsball.actions:\n",
        "      print(foolsball.step(act))\n",
        "      print()\n",
        "      foolsball.render()\n",
        "    elif act == 'r':\n",
        "      print(foolsball.reset())\n",
        "      print()\n",
        "      foolsball.render()\n",
        "    elif act == 'x':\n",
        "      break\n",
        "    else:\n",
        "      print(f'Invalid input:{act}')\n",
        "  except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyzJFjD5FRov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}